{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install anvil-uplink"
      ],
      "metadata": {
        "id": "6Mwp08wiZRvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import anvil.server\n",
        "anvil.server.connect('server_6CU44U7Y7SWNGRX2APBMPKTK-P3ND7TTTPMEKZ7IK')"
      ],
      "metadata": {
        "id": "9ix9J9ZIZbUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dBcwQF46ve6"
      },
      "outputs": [],
      "source": [
        "!pip install -q torch transformers sentencepiece indic-nlp-library\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/VarunGumma/IndicTransToolkit\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "kO9V5CaNXDDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q flash-attn --no-build-isolation\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "tjA9tue9XEEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required components\n",
        "!git clone https://github.com/anoopkunchukuttan/indic_nlp_resources.git"
      ],
      "metadata": {
        "collapsed": true,
        "id": "avSMFHFpXFIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/indic_nlp_resources')"
      ],
      "metadata": {
        "id": "7jkSKzG1Q3Xi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IndicLID -> Getting the code of the input language**"
      ],
      "metadata": {
        "id": "i61rQp9QbZdg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install fasttext\n",
        "!pip3 install transformers"
      ],
      "metadata": {
        "collapsed": true,
        "id": "E6qcHiLAayiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/AI4Bharat/IndicLID.git"
      ],
      "metadata": {
        "collapsed": true,
        "id": "gP8Lf45Va1hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/IndicLID/Inference\""
      ],
      "metadata": {
        "id": "y_1r5295a4ba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir models\n",
        "%cd \"/content/IndicLID/Inference/models\""
      ],
      "metadata": {
        "id": "uB1fDP2_a57o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/AI4Bharat/IndicLID/releases/download/v1.0/indiclid-bert.zip\n",
        "!wget https://github.com/AI4Bharat/IndicLID/releases/download/v1.0/indiclid-ftn.zip\n",
        "!wget https://github.com/AI4Bharat/IndicLID/releases/download/v1.0/indiclid-ftr.zip"
      ],
      "metadata": {
        "collapsed": true,
        "id": "1lZ3WBpVa7ez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip indiclid-bert.zip\n",
        "!unzip indiclid-ftn.zip\n",
        "!unzip indiclid-ftr.zip"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9IrhHUbWa86T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd \"/content/IndicLID/\"\n",
        "%cd \"/content/IndicLID/Inference\""
      ],
      "metadata": {
        "id": "aZpE0Oxca_RK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Language Convertion**"
      ],
      "metadata": {
        "id": "xrAbJn24bgSH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Combined Code -> Regional text to English**"
      ],
      "metadata": {
        "id": "HtescLVUqagB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from IndicTransToolkit import IndicProcessor\n",
        "from ai4bharat.IndicLID import IndicLID\n",
        "import os\n",
        "\n",
        "os.environ['TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD'] = '1'\n",
        "# Define device\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Initialize language detection model\n",
        "lid_model = IndicLID()\n",
        "\n",
        "# Load translation model and tokenizer\n",
        "model_name = \"ai4bharat/indictrans2-indic-en-1B\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "    model_name,\n",
        "    trust_remote_code=True,\n",
        "    torch_dtype=torch.float16 if DEVICE == \"cuda\" else torch.float32\n",
        ").to(DEVICE)\n",
        "\n",
        "# Initialize processor\n",
        "ip = IndicProcessor(inference=True)\n",
        "\n",
        "# Mapping of LID language outputs to IndicTrans language codes\n",
        "# This mapping connects the language detected by IndicLID to the code expected by IndicTrans\n",
        "lid_to_indictrans_mapping = {\n",
        "    'Hindi': 'hin_Deva',\n",
        "    'Bengali': 'ben_Beng',\n",
        "    'Telugu': 'tel_Telu',\n",
        "    'Marathi': 'mar_Deva',\n",
        "    'Tamil': 'tam_Taml',\n",
        "    'Urdu': 'urd_Arab',\n",
        "    'Gujarati': 'guj_Gujr',\n",
        "    'Kannada': 'kan_Knda',\n",
        "    'Odia': 'ori_Orya',\n",
        "    'Punjabi': 'pan_Guru',\n",
        "    'Malayalam': 'mal_Mlym',\n",
        "    'Assamese': 'asm_Beng',\n",
        "    'Maithili': 'mai_Deva',\n",
        "    'Santali': 'sat_Olck',\n",
        "    'Kashmiri': 'kas_Arab',\n",
        "    'Nepali': 'npi_Deva',\n",
        "    'Sindhi': 'snd_Arab',\n",
        "    'Dogri': 'doi_Deva',\n",
        "    'Konkani': 'kok_Deva',\n",
        "    'Manipuri': 'mni_Beng',\n",
        "    'Bodo': 'brx_Deva',\n",
        "    'Sanskrit': 'san_Deva'\n",
        "}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GzaFlKuvny_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_and_translate(input_text):\n",
        "    \"\"\"\n",
        "    Detect the language of input text and translate it to English\n",
        "\n",
        "    Args:\n",
        "        input_text (str): Text in any Indian language\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing original text, detected language, and translated text\n",
        "    \"\"\"\n",
        "    # Detect language\n",
        "    batch_size = 1\n",
        "    lid_output = lid_model.batch_predict([input_text], batch_size)\n",
        "\n",
        "    # Extract detected language\n",
        "    detected_lang = lid_output[0][1]  # First element is language name\n",
        "    confidence = lid_output[0][2]     # Second element is confidence score\n",
        "\n",
        "\n",
        "\n",
        "    # If language is not detected or not in our mapping\n",
        "    if not detected_lang:\n",
        "        print(\"Here?\")\n",
        "        return {\n",
        "            \"original_text\": input_text,\n",
        "            \"detected_language\": detected_lang if detected_lang else \"Unknown\",\n",
        "            \"translated_text\": \"Could not translate - language not supported or detected\",\n",
        "            \"confidence\": confidence if detected_lang else 0.0\n",
        "        }\n",
        "\n",
        "    # Get the corresponding language code for translation\n",
        "    src_lang = detected_lang\n",
        "\n",
        "    try:\n",
        "        # Preprocess input text\n",
        "        print(\"Try\")\n",
        "        batch = ip.preprocess_batch([input_text], src_lang=src_lang, tgt_lang=\"eng_Latn\")\n",
        "\n",
        "        # Tokenize and move to correct device\n",
        "        print(\"Try again\")\n",
        "        inputs = tokenizer(batch, truncation=True, padding=\"longest\", return_tensors=\"pt\").to(DEVICE)\n",
        "\n",
        "        # Generate translation\n",
        "        with torch.no_grad():\n",
        "            print(\"We are here\")\n",
        "            generated_tokens = model.generate(**inputs, max_length=256, num_beams=5)\n",
        "\n",
        "        # Decode the translation\n",
        "        with tokenizer.as_target_tokenizer():\n",
        "            decoded_translation = tokenizer.batch_decode(\n",
        "                generated_tokens.cpu().tolist(),\n",
        "                skip_special_tokens=True,\n",
        "                clean_up_tokenization_spaces=True\n",
        "            )[0]\n",
        "\n",
        "        # Postprocess and store the translation\n",
        "        translated_text = ip.postprocess_batch([decoded_translation], lang=\"eng_Latn\")[0]\n",
        "\n",
        "        return {\n",
        "            \"original_text\": input_text,\n",
        "            \"detected_language\": detected_lang,\n",
        "            \"translated_text\": translated_text,\n",
        "            \"confidence\": confidence\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing sentence in {src_lang}: {e}\")\n",
        "        return {\n",
        "            \"original_text\": input_text,\n",
        "            \"detected_language\": detected_lang,\n",
        "            \"translated_text\": f\"Translation failed: {str(e)}\",\n",
        "            \"confidence\": confidence\n",
        "        }\n"
      ],
      "metadata": {
        "id": "eqPNuYOGsytU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Test with multiple inputs\n",
        "    test_inputs = [\n",
        "    \"मैं गर्भवती हूँ। मेरी आय 15000 रुपये प्रति माह है। मैं किन योजनाओं का लाभ उठा सकती हूँ?\",  # Hindi\n",
        "    \"আমি গর্ভবতী। আমার আয় প্রতি মাসে ১৫০০০ টাকা। আমি কোন কোন স্কিমের সুবিধা নিতে পারি?\",  # Bengali\n",
        "    \"నేను గర్భిణి ని. నా ఆదాయం నెలకు 15000 రూపాయలు. నేను ఏ పథకాలను పొందగలను?\",  # Telugu\n",
        "    \"मी गर्भवती आहे. माझे उत्पन्न प्रति महिना १५००० रुपये आहे. मी कोणत्या योजना मिळवू शकते?\",  # Marathi\n",
        "    \"நான் கர்ப்பிணி. என் வருமானம் மாதம் 15000 ரூபாய். எந்த திட்டங்களை பெற முடியும்?\",  # Tamil\n",
        "    \"میں حاملہ ہوں۔ میری آمدنی 15000 روپے ماہانہ ہے۔ میں کون سی اسکیمیں حاصل کر سکتی ہوں؟\",  # Urdu\n",
        "    \"હું ગર્ભવતી છું. મારી આવક 15000 રૂપિયા પ્રતિ મહિને છે. હું કઈ યોજનાઓનો લાભ લઈ શકું?\",  # Gujarati\n",
        "    \"ನಾನು ಗರ್ಭಿಣಿ. ನನ್ನ ಆದಾಯ ತಿಂಗಳಿಗೆ 15000 ರೂಪಾಯಿ. ನಾನು ಯಾವ ಯೋಜನೆಗಳನ್ನು ಪಡೆಯಬಹುದು?\",  # Kannada\n",
        "    \"ମୁଁ ଗର୍ଭବତୀ । ମୋର ରୋଜଗାର ମାସକୁ ୧୫୦୦୦ ଟଙ୍କା । ମୁଁ କେଉଁ ଯୋଜନାର ଲାଭ ନେଇପାରିବି?\",  # Odia\n",
        "    \"ਮੈਂ ਗਰਭਵਤੀ ਹਾਂ। ਮੇਰੀ ਆਮਦਨ 15000 ਰੁਪਏ ਪ੍ਰਤੀ ਮਹੀਨਾ ਹੈ। ਮੈਂ ਕਿਹੜੀਆਂ ਯੋਜਨਾਵਾਂ ਦਾ ਲਾਭ ਲੈ ਸਕਦੀ ਹਾਂ?\",  # Punjabi\n",
        "    \"ഞാൻ ഗർഭിണിയാണ്. എന്റെ വരുമാനം പ്രതിമാസം 15000 രൂപയാണ്. ഞാൻ ഏത് പദ്ധതികൾ പ്രയോജനപ്പെടുത്താൻ കഴിയും?\",  # Malayalam\n",
        "    \"মই গৰ্ভৱতী। মোৰ মাহেকীয়া আয় ১৫০০০ টকা। কোন স্কীমসমূহ মই লাভ কৰিব পাৰোঁ?\",  # Assamese\n",
        "    \"हम गर्भवती छी। हमर आय 15000 टाका प्रति माह अछि। हम किन योजनाक लाभ उठा सकैत छी?\",  # Maithili\n",
        "    \"Ang gayeraak'na. Anga aay 15000 rupiya mahina. Ang kon'ko scheme horom availing kana?\",  # Santali\n",
        "    \"بے حامِلہ آہِم۔ میژھ آمدَن 15000 روپَیہ ماہانہ آہے۔ بے کوژ سکیمز حاصل کرِتھ سُنہ؟\",  # Kashmiri\n",
        "    \"म गर्भवती छु। मेरो आम्दानी प्रति महिना १५००० रुपैयाँ छ। म कुन योजनाहरू प्राप्त गर्न सक्छु?\",  # Nepali\n",
        "    \"آءٌ حامله آھيان. منھنجو آمدني 15000 رپيا مھينا آھي. ڪھڙيون اسڪيمون حاصل ڪري سگھان ٿي؟\",  # Sindhi\n",
        "    \"मैं गर्भवती हूँ। मेरी आय 15000 रुपये प्रति महीना है। मैं किन योजनाओं का लाभ उठा सकती हूँ?\",  # Dogri\n",
        "    \"हांव गर्भवती आसा. माझो उत्पन्न 15000 रुपये प्रति म्हयना. हांव कोणाच्या योजना लाबू शकता?\",  # Konkani\n",
        "    \"èi chanu thoklaba nupi ni. eiga chatpa thoujannasi tháng 15000-gi. eiga karigumba scheme-sing eigi oiriba ngamgani?\",  # Manipuri\n",
        "    \"आं गोर्बोआव दं। आंनि आयआ दानफ्रोमबो 15000 रां। आं बबे स्किमफोरनि मुलाम्फा लानो हागोन?\",  # Bodo\n",
        "    \"अहम् गर्भिणी अस्मि। मम आयः मासे १५००० रूप्यकाणि अस्ति। अहम् कासु योजनानाम् लाभम् प्राप्नुयाम्?\"  # Sanskrit\n",
        "]\n",
        "\n",
        "    for i, text in enumerate(test_inputs):\n",
        "        print(f\"\\nTesting input {i+1}:\")\n",
        "        result = detect_and_translate(text)\n",
        "        print(result)\n",
        "        print(f\"Original: {result['original_text']}\")\n",
        "        print(f\"Detected Language: {result['detected_language']} (confidence: {result['confidence']})\")\n",
        "        print(f\"Translation: {result['translated_text']}\")"
      ],
      "metadata": {
        "id": "0Dr5zRavs4Lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**AUDIO**"
      ],
      "metadata": {
        "id": "w3pqTJT-uImL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torchaudio onnx onnxruntime onnxruntime-gpu\n"
      ],
      "metadata": {
        "id": "I7ADUm4oqYbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U openai-whisper"
      ],
      "metadata": {
        "id": "DY_kfBYcj020"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Breaking into pieces -> Regional Speech to English text conversion**"
      ],
      "metadata": {
        "id": "Pv5YQ3thDY9O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOTE -> Add an audio file to see the output"
      ],
      "metadata": {
        "id": "HHbl3Aow37nG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "from transformers import AutoModel, AutoProcessor, AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from transformers import Wav2Vec2ForSequenceClassification, AutoFeatureExtractor, AutoConfig\n",
        "from IndicTransToolkit import IndicProcessor\n",
        "import numpy as np\n",
        "import time\n",
        "import gc\n",
        "import whisper\n",
        "from transformers import Wav2Vec2ForCTC\n",
        "\n",
        "# Set device\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "# Memory optimization function\n",
        "def optimize_memory():\n",
        "    # Clear CUDA cache if using GPU\n",
        "    if DEVICE == \"cuda\":\n",
        "        torch.cuda.empty_cache()\n",
        "    # Force garbage collection\n",
        "    gc.collect()\n",
        "\n",
        "# Initialize processor\n",
        "ip = IndicProcessor(inference=True)\n",
        "\n",
        "# === LANGUAGE DETECTION FUNCTIONS ===\n",
        "\n",
        "def load_language_detection_model():\n",
        "    \"\"\"\n",
        "    Load the MMS-LID model and feature extractor.\n",
        "    Returns:\n",
        "        tuple: (model, feature_extractor, languages)\n",
        "    \"\"\"\n",
        "    print(\"Loading MMS-LID model...\")\n",
        "    model_name = \"facebook/mms-lid-126\"\n",
        "    model = Wav2Vec2ForSequenceClassification.from_pretrained(model_name).to(DEVICE)\n",
        "    feature_extractor = AutoFeatureExtractor.from_pretrained(model_name)\n",
        "    languages = model.config.id2label\n",
        "    return model, feature_extractor, languages\n",
        "\n",
        "def get_audio_info(audio_path):\n",
        "    \"\"\"\n",
        "    Get information about the audio file.\n",
        "    Args:\n",
        "        audio_path (str): Path to the audio file\n",
        "    Returns:\n",
        "        tuple: (waveform, sample_rate, total_duration)\n",
        "    \"\"\"\n",
        "    waveform, sample_rate = torchaudio.load(audio_path)\n",
        "    total_duration = waveform.shape[1] / sample_rate\n",
        "    return waveform, sample_rate, total_duration\n",
        "\n",
        "def determine_chunk_parameters(total_duration, waveform_length, sample_rate, chunk_duration, chunk_offset):\n",
        "    \"\"\"\n",
        "    Determine the parameters for audio chunking.\n",
        "    \"\"\"\n",
        "    use_entire_audio = False\n",
        "\n",
        "    # Check if audio is shorter than the requested chunk duration\n",
        "    if total_duration <= chunk_duration:\n",
        "        # Use the entire audio file\n",
        "        frame_offset = 0\n",
        "        num_frames = waveform_length\n",
        "        chunk_offset = 0\n",
        "        processing_duration = total_duration\n",
        "        use_entire_audio = True\n",
        "        print(f\"Audio duration ({total_duration:.2f}s) is shorter than requested chunk duration ({chunk_duration:.2f}s)\")\n",
        "        print(f\"Processing entire audio file\")\n",
        "    else:\n",
        "        # Process only a chunk\n",
        "        # Determine offset position for the chunk (if not provided)\n",
        "        if chunk_offset is None:\n",
        "            # Default to 1/3 of the way through the file, which often contains clearer speech\n",
        "            chunk_offset = min(total_duration / 3, total_duration / 2)\n",
        "\n",
        "        # Make sure we have enough audio left for the chunk\n",
        "        if chunk_offset + chunk_duration > total_duration:\n",
        "            chunk_offset = max(0, total_duration - chunk_duration)\n",
        "\n",
        "        # Convert offset to frames\n",
        "        frame_offset = int(chunk_offset * sample_rate)\n",
        "        num_frames = int(chunk_duration * sample_rate)\n",
        "        processing_duration = chunk_duration\n",
        "\n",
        "        # Make sure we don't request more frames than available\n",
        "        if frame_offset + num_frames > waveform_length:\n",
        "            num_frames = max(0, waveform_length - frame_offset)\n",
        "            processing_duration = num_frames / sample_rate\n",
        "\n",
        "        print(f\"Processing {processing_duration:.2f}s of audio at position {chunk_offset:.2f}s\")\n",
        "        print(f\"Original file duration: {total_duration:.2f}s\")\n",
        "\n",
        "    return frame_offset, num_frames, chunk_offset, processing_duration, use_entire_audio\n",
        "\n",
        "def preprocess_audio(waveform, sample_rate, feature_extractor):\n",
        "    \"\"\"\n",
        "    Preprocess the audio waveform for the model.\n",
        "    \"\"\"\n",
        "    # Convert to mono if stereo\n",
        "    if waveform.shape[0] > 1:\n",
        "        waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
        "\n",
        "    # Resample if necessary\n",
        "    if sample_rate != feature_extractor.sampling_rate:\n",
        "        resampler = torchaudio.transforms.Resample(sample_rate, feature_extractor.sampling_rate)\n",
        "        waveform = resampler(waveform)\n",
        "\n",
        "    # Convert to numpy array (expected by feature extractor)\n",
        "    speech_array = waveform.squeeze().numpy()\n",
        "\n",
        "    # Extract features\n",
        "    inputs = feature_extractor(\n",
        "        speech_array,\n",
        "        sampling_rate=feature_extractor.sampling_rate,\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(DEVICE)\n",
        "\n",
        "    return inputs\n",
        "\n",
        "def get_language_predictions(model, inputs, languages, top_k=1):\n",
        "    \"\"\"\n",
        "    Get language predictions from the model.\n",
        "    \"\"\"\n",
        "    # Get model prediction\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "    # Apply softmax to get probabilities\n",
        "    probs = torch.nn.functional.softmax(logits, dim=-1).squeeze().cpu().numpy()\n",
        "\n",
        "    # Get top-k predictions\n",
        "    top_indices = np.argsort(probs)[::-1][:top_k]\n",
        "    results = []\n",
        "\n",
        "    for idx in top_indices:\n",
        "        lang_code = languages[idx]\n",
        "        probability = probs[idx]\n",
        "        results.append((lang_code, probability))\n",
        "\n",
        "    return results\n",
        "\n",
        "def detect_language(audio_path, chunk_duration=5.0, chunk_offset=None, top_k=1):\n",
        "    \"\"\"\n",
        "    Detect the language of an audio file using the MMS-LID model.\n",
        "    Returns:\n",
        "        tuple: (detected_language_code, probability, processing_time)\n",
        "    \"\"\"\n",
        "    print(\"Detecting language...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Step 1: Load the model and feature extractor\n",
        "    model, feature_extractor, languages = load_language_detection_model()\n",
        "\n",
        "    # Step 2: Get audio information\n",
        "    waveform, sample_rate, total_duration = get_audio_info(audio_path)\n",
        "\n",
        "    # Step 3: Determine chunk parameters\n",
        "    frame_offset, num_frames, chunk_offset, processing_duration, use_entire_audio = determine_chunk_parameters(\n",
        "        total_duration, waveform.shape[1], sample_rate, chunk_duration, chunk_offset\n",
        "    )\n",
        "\n",
        "    # Step 4: Extract the audio chunk if not using entire audio\n",
        "    if not use_entire_audio:\n",
        "        waveform, sample_rate = torchaudio.load(\n",
        "            audio_path,\n",
        "            frame_offset=frame_offset,\n",
        "            num_frames=num_frames\n",
        "        )\n",
        "\n",
        "    # Step 5: Preprocess the audio\n",
        "    inputs = preprocess_audio(waveform, sample_rate, feature_extractor)\n",
        "\n",
        "    # Step 6: Get language predictions\n",
        "    results = get_language_predictions(model, inputs, languages, top_k)\n",
        "\n",
        "    # Calculate processing time\n",
        "    end_time = time.time()\n",
        "    processing_time = end_time - start_time\n",
        "\n",
        "    # Get the top language\n",
        "    top_lang, top_prob = results[0]\n",
        "    print(f\"Detected language: {top_lang} with {top_prob*100:.2f}% confidence\")\n",
        "\n",
        "    # Clean up\n",
        "    del model\n",
        "    optimize_memory()\n",
        "\n",
        "    return top_lang, top_prob, processing_time\n",
        "\n",
        "# === TRANSCRIPTION FUNCTIONS ===\n",
        "\n",
        "def transcribe_english_audio(audio_path):\n",
        "    \"\"\"\n",
        "    Transcribe English speech from audio to text using Whisper.\n",
        "    \"\"\"\n",
        "    print(\"Transcribing English audio...\")\n",
        "\n",
        "    # Load the base English-only model\n",
        "    model = whisper.load_model(\"tiny.en\")  # Options: tiny.en, base.en, small.en\n",
        "\n",
        "    # Transcribe with language explicitly set to English\n",
        "    result = model.transcribe(audio_path, language=\"en\", fp16=False)\n",
        "\n",
        "    # Clean up\n",
        "    del model\n",
        "    optimize_memory()\n",
        "\n",
        "    return result[\"text\"]\n",
        "\n",
        "def process_audio_in_chunks(model, audio_path, language_code, decoding_method=\"rnnt\", chunk_duration=30):\n",
        "    \"\"\"\n",
        "    Process audio in chunks using IndicConformer with the detected language.\n",
        "    \"\"\"\n",
        "    # Map MMS-LID language codes to IndicConformer codes\n",
        "    indic_lang_mapping = {\n",
        "        \"eng\": \"en\",\n",
        "        \"asm\": \"as\",         # Assamese\n",
        "        \"ben\": \"bn\",         # Bengali\n",
        "        \"brx\": \"brx\",        # Bodo\n",
        "        \"doi\": \"doi\",        # Dogri\n",
        "        \"guj\": \"gu\",         # Gujarati\n",
        "        \"hin\": \"hi\",         # Hindi\n",
        "        \"kan\": \"kn\",         # Kannada\n",
        "        \"kas\": \"ks\",         # Kashmiri\n",
        "        \"gom\": \"kok\",        # Konkani\n",
        "        \"mai\": \"mai\",        # Maithili\n",
        "        \"mal\": \"ml\",         # Malayalam\n",
        "        \"mni_Mtei\": \"mni\",   # Manipuri\n",
        "        \"mar\": \"mr\",         # Marathi\n",
        "        \"npi\": \"ne\",         # Nepali\n",
        "        \"ori\": \"or\",         # Odia\n",
        "        \"pan_Guru\": \"pa\",    # Punjabi\n",
        "        \"san_Deva\": \"sa\",    # Sanskrit\n",
        "        \"sat_Olck\": \"sat\",   # Santali\n",
        "        \"snd_Arab\": \"sd\",    # Sindhi\n",
        "        \"tam_Taml\": \"ta\",    # Tamil\n",
        "        \"tel_Telu\": \"te\",    # Telugu\n",
        "        \"urd_Arab\": \"ur\"     # Urdu\n",
        "    }\n",
        "\n",
        "    # Map the language code\n",
        "    indic_lang = indic_lang_mapping.get(language_code, \"hi\")  # Default to Hindi if mapping not found\n",
        "    print(f\"Using language code for transcription: {indic_lang}\")\n",
        "\n",
        "    # Load audio file\n",
        "    wav, sr = torchaudio.load(audio_path)\n",
        "\n",
        "    # Resample to 16kHz if needed\n",
        "    target_sample_rate = 16000\n",
        "    if sr != target_sample_rate:\n",
        "        resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=target_sample_rate)\n",
        "        wav = resampler(wav)\n",
        "\n",
        "    # Convert stereo to mono if necessary\n",
        "    if wav.shape[0] > 1:\n",
        "        wav = torch.mean(wav, dim=0, keepdim=True)\n",
        "\n",
        "    # Calculate chunk size (in samples)\n",
        "    chunk_size = int(chunk_duration * target_sample_rate)\n",
        "    total_samples = wav.shape[1]\n",
        "\n",
        "    # Process in chunks\n",
        "    transcriptions = []\n",
        "    for i in range(0, total_samples, chunk_size):\n",
        "        # Extract chunk\n",
        "        end_idx = min(i + chunk_size, total_samples)\n",
        "        chunk = wav[:, i:end_idx]\n",
        "\n",
        "        # Process chunk with detected language\n",
        "        try:\n",
        "            with torch.no_grad():  # Disable gradient tracking to save memory\n",
        "                transcription = model(chunk, indic_lang, decoding_method)\n",
        "            transcriptions.append(transcription)\n",
        "\n",
        "            # Free memory\n",
        "            optimize_memory()\n",
        "\n",
        "            print(f\"Processed chunk {i//chunk_size + 1}/{(total_samples + chunk_size - 1)//chunk_size}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing chunk {i//chunk_size + 1}: {e}\")\n",
        "\n",
        "    # Combine all transcriptions\n",
        "    return \" \".join(transcriptions)\n",
        "\n",
        "def transcribe_audio(audio_path, language_code):\n",
        "    \"\"\"\n",
        "    Transcribe audio using the detected language.\n",
        "    \"\"\"\n",
        "    if language_code == \"eng\":\n",
        "        # For English, use Whisper\n",
        "        return transcribe_english_audio(audio_path)\n",
        "    else:\n",
        "        # For Indic languages, use IndicConformer\n",
        "        try:\n",
        "            # Load model with memory optimization\n",
        "            print(\"Loading IndicConformer model...\")\n",
        "            model = AutoModel.from_pretrained(\n",
        "                \"ai4bharat/indic-conformer-600m-multilingual\",\n",
        "                trust_remote_code=True,\n",
        "                torch_dtype=torch.float16 if DEVICE == \"cuda\" else torch.float32\n",
        "            ).to(DEVICE)\n",
        "            model.eval()  # Set to evaluation mode\n",
        "\n",
        "            optimize_memory()\n",
        "\n",
        "            print(\"Starting RNNT transcription...\")\n",
        "            rnnt_result = process_audio_in_chunks(model, audio_path, language_code, \"rnnt\")\n",
        "            print(f\"RNNT Transcription: {rnnt_result}\")\n",
        "\n",
        "            # Clean up\n",
        "            del model\n",
        "            optimize_memory()\n",
        "\n",
        "            return rnnt_result\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during transcription: {e}\")\n",
        "            return None\n",
        "\n",
        "# === TRANSLATION FUNCTIONS ===\n",
        "\n",
        "def load_translation_model():\n",
        "    \"\"\"\n",
        "    Load the IndicTrans2 translation model.\n",
        "    \"\"\"\n",
        "    print(\"Loading IndicTrans2 model...\")\n",
        "    model_name = \"ai4bharat/indictrans2-indic-en-1B\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "        model_name,\n",
        "        trust_remote_code=True,\n",
        "        torch_dtype=torch.float16 if DEVICE == \"cuda\" else torch.float32\n",
        "    ).to(DEVICE)\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "def translate_to_english(text, src_lang):\n",
        "    \"\"\"\n",
        "    Translate text from source language to English using IndicTrans2.\n",
        "    \"\"\"\n",
        "    # Map MMS-LID language codes to IndicTrans2 codes\n",
        "    indictrans_lang_mapping = {\n",
        "        \"eng\": \"eng_Latn\",\n",
        "        \"asm\": \"asm_Beng\",   # Assamese\n",
        "        \"ben\": \"ben_Beng\",   # Bengali\n",
        "        \"brx\": \"brx_Deva\",   # Bodo\n",
        "        \"doi\": \"doi_Deva\",   # Dogri\n",
        "        \"guj\": \"guj_Gujr\",   # Gujarati\n",
        "        \"hin\": \"hin_Deva\",   # Hindi\n",
        "        \"kan\": \"kan_Knda\",   # Kannada\n",
        "        \"kas\": \"kas_Deva\",   # Kashmiri\n",
        "        \"gom\": \"gom_Deva\",   # Konkani\n",
        "        \"mai\": \"mai_Deva\",   # Maithili\n",
        "        \"mal\": \"mal_Mlym\",   # Malayalam\n",
        "        \"mni_Mtei\": \"mni_Mtei\", # Manipuri\n",
        "        \"mar\": \"mar_Deva\",   # Marathi\n",
        "        \"npi\": \"nep_Deva\",   # Nepali\n",
        "        \"ori\": \"ory_Orya\",   # Odia\n",
        "        \"pan_Guru\": \"pan_Guru\", # Punjabi\n",
        "        \"san_Deva\": \"san_Deva\", # Sanskrit\n",
        "        \"sat_Olck\": \"sat_Olck\", # Santali\n",
        "        \"snd_Arab\": \"snd_Arab\", # Sindhi\n",
        "        \"tam_Taml\": \"tam_Taml\", # Tamil\n",
        "        \"tel_Telu\": \"tel_Telu\", # Telugu\n",
        "        \"urd_Arab\": \"urd_Arab\"  # Urdu\n",
        "    }\n",
        "\n",
        "    # Get the mapped language code for IndicTrans2\n",
        "    src_lang_code = indictrans_lang_mapping.get(src_lang, \"hin_Deva\")  # Default to Hindi if not found\n",
        "\n",
        "    # If already English, return the text\n",
        "    if src_lang == \"eng\":\n",
        "        return text\n",
        "\n",
        "    try:\n",
        "        # Load translation model\n",
        "        model, tokenizer = load_translation_model()\n",
        "\n",
        "        # Preprocess input text for translation\n",
        "        batch = ip.preprocess_batch([text], src_lang=src_lang_code, tgt_lang=\"eng_Latn\")\n",
        "\n",
        "        # Tokenize the preprocessed batch\n",
        "        inputs = tokenizer(batch, truncation=True, padding=\"longest\", return_tensors=\"pt\").to(DEVICE)\n",
        "\n",
        "        # Generate translation\n",
        "        with torch.no_grad():\n",
        "            generated_tokens = model.generate(**inputs, max_length=256, num_beams=5)\n",
        "\n",
        "        # Decode the translation\n",
        "        with tokenizer.as_target_tokenizer():\n",
        "            decoded_translation = tokenizer.batch_decode(\n",
        "                generated_tokens.cpu().tolist(),\n",
        "                skip_special_tokens=True,\n",
        "                clean_up_tokenization_spaces=True,\n",
        "            )[0]\n",
        "\n",
        "        translated_text = ip.postprocess_batch([decoded_translation], lang=\"eng_Latn\")[0]\n",
        "\n",
        "        # Clean up\n",
        "        del model, tokenizer\n",
        "        optimize_memory()\n",
        "\n",
        "        return translated_text\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during translation: {e}\")\n",
        "        return f\"Translation failed: {str(e)}\"\n",
        "\n",
        "# === MAIN PROCESSING FUNCTION ===\n",
        "\n",
        "def process_audio_with_auto_language(audio_path):\n",
        "    \"\"\"\n",
        "    Complete end-to-end processing:\n",
        "    1. Detect language\n",
        "    2. Transcribe audio in detected language\n",
        "    3. Translate transcription to English\n",
        "    \"\"\"\n",
        "    # Step 1: Detect language\n",
        "    detected_lang, confidence, detect_time = detect_language(audio_path)\n",
        "    print(f\"Language detection completed in {detect_time:.2f}s\")\n",
        "\n",
        "    # Step 2: Transcribe audio in detected language\n",
        "    transcription = transcribe_audio(audio_path, detected_lang)\n",
        "    if not transcription:\n",
        "        return {\n",
        "            \"detected_language\": detected_lang,\n",
        "            \"confidence\": confidence,\n",
        "            \"transcription\": None,\n",
        "            \"translation\": None,\n",
        "            \"error\": \"Transcription failed\"\n",
        "        }\n",
        "\n",
        "    # Step 3: Translate to English (if not already English)\n",
        "    if detected_lang == \"eng\":\n",
        "        translation = transcription\n",
        "    else:\n",
        "        translation = translate_to_english(transcription, detected_lang)\n",
        "\n",
        "    return {\n",
        "        \"detected_language\": detected_lang,\n",
        "        \"confidence\": f\"{confidence*100:.2f}%\",\n",
        "        \"transcription\": transcription,\n",
        "        \"translation\": translation\n",
        "    }\n",
        "\n",
        "# Main function\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    audio_file = \"/content/New Recording 2.wav\"  # Replace with your audio file path\n",
        "\n",
        "    print(\"Starting audio processing pipeline...\")\n",
        "    results = process_audio_with_auto_language(audio_file)\n",
        "\n",
        "    print(\"\\n===== RESULTS =====\")\n",
        "    print(f\"Detected Language: {results['detected_language']} (Confidence: {results['confidence']})\")\n",
        "    print(f\"\\nOriginal Transcription: {results['transcription']}\")\n",
        "    print(f\"\\nEnglish Translation: {results['translation']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoTCTXmHkzy2",
        "outputId": "b827b8be-0424-4ef6-f794-8b07cf047966"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Starting audio processing pipeline...\n",
            "Detecting language...\n",
            "Loading MMS-LID model...\n",
            "Processing 5.00s of audio at position 3.60s\n",
            "Original file duration: 10.79s\n",
            "Detected language: eng with 77.46% confidence\n",
            "Language detection completed in 5.83s\n",
            "Transcribing English audio...\n",
            "\n",
            "===== RESULTS =====\n",
            "Detected Language: eng (Confidence: 77.46%)\n",
            "\n",
            "Original Transcription:  Hello ladies and gentlemen today I'm making this way file to see if my speech to text conversion app is working or not Thank you for giving me a sad time and I'll see you around. Thank you\n",
            "\n",
            "English Translation:  Hello ladies and gentlemen today I'm making this way file to see if my speech to text conversion app is working or not Thank you for giving me a sad time and I'll see you around. Thank you\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To extract certain info from English Text**"
      ],
      "metadata": {
        "id": "mNPqtNSur7p7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "54kGQXRZr7TO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.enable()\n",
        "def optimize_memory():\n",
        "    # Clear CUDA cache if using GPU\n",
        "    if DEVICE == \"cuda\":\n",
        "        torch.cuda.empty_cache()\n",
        "    # Force garbage collection\n",
        "    gc.collect()\n",
        "\n"
      ],
      "metadata": {
        "id": "a5DlWXRcl_3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iEY8m9bMl_qr"
      }
    }
  ]
}